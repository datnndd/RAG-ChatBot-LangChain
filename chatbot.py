import os
import gradio as gr
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser

# =========================
# CONFIG
# =========================
load_dotenv()
VECTOR_DB_DIR = "vector_store_chroma"

# =========================
# INIT COMPONENTS
# =========================
def initialize_components():
    """Kh·ªüi t·∫°o LLM, embeddings v√† vector store"""
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/text-embedding-004"
    )

    #Thay m√¥ h√¨nh LLM n·∫øu b·ªã h·∫°n ch·∫ø
    #gemini-2.5-flash-lite
    #gemini-3-flash
    #gemini-2.5-flash
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.3
    )

    if not os.path.exists(VECTOR_DB_DIR):
        raise RuntimeError("Ch∆∞a c√≥ Vector DB. H√£y ch·∫°y build_vector_db.py tr∆∞·ªõc!")

    vector_db = Chroma(
        persist_directory=VECTOR_DB_DIR,
        embedding_function=embeddings
    )

    retriever = vector_db.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 5}
    )

    return llm, retriever


def format_docs(docs):
    """Format danh s√°ch documents th√†nh chu·ªói context"""
    formatted = []
    for doc in docs:
        meta = doc.metadata
        if meta.get("doc_type") == "product":
            formatted.append(
                f"S·∫£n ph·∫©m: {meta.get('product_name')}\n"
                f"- Gi√°: {meta.get('price')}ƒë\n"
                f"- M√†u: {meta.get('color')}\n"
                f"- Size: {meta.get('size')}\n"
                f"- T·ªìn kho: {meta.get('stock')}\n"
                f"- ƒê√°nh gi√°: {meta.get('rating')}\n"
                f"- M√¥ t·∫£: {doc.page_content}"
            )
        else:
            formatted.append(f"T√†i li·ªáu ({meta.get('source', 'unknown')}): {doc.page_content}")
    return "\n\n---\n".join(formatted)


def format_sources(docs):
    """Format ngu·ªìn tham kh·∫£o t·ª´ documents"""
    sources = set()
    for doc in docs:
        meta = doc.metadata
        if meta.get("doc_type") == "product":
            sources.add(
                f"üõçÔ∏è {meta.get('product_name')} | "
                f"{meta.get('price'):,}ƒë | "
                f"{meta.get('color')} | "
                f"Size {meta.get('size')} | "
                f"T·ªìn: {meta.get('stock')}"
            )
        else:
            sources.add(f"üìÑ {meta.get('source', 'unknown')}")
    return sources


# =========================
# INIT LLM & RETRIEVER
# =========================
llm, retriever = initialize_components()

# L∆∞u l·ªãch s·ª≠ chat
chat_history = []

# Prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", """B·∫°n l√† tr·ª£ l√Ω AI t∆∞ v·∫•n th·ªùi trang cho c·ª≠a h√†ng Uqilo.
Nhi·ªám v·ª• c·ªßa b·∫°n:
- T∆∞ v·∫•n s·∫£n ph·∫©m d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p
- Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ th√¥ng tin c√¥ng ty
- G·ª£i √Ω s·∫£n ph·∫©m ph√π h·ª£p v·ªõi nhu c·∫ßu kh√°ch h√†ng

Th√¥ng tin tham kh·∫£o:
{context}

L∆∞u √Ω:
- Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p
- N·∫øu kh√¥ng c√≥ th√¥ng tin, h√£y n√≥i r√µ l√† kh√¥ng bi·∫øt
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp"""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{question}")
])


# =========================
# CHAT HANDLER
# =========================
def chat_handler(message, history):
    """X·ª≠ l√Ω tin nh·∫Øn t·ª´ Gradio"""
    global chat_history
    
    if not message.strip():
        return ""
    
    try:
        # L·∫•y documents
        docs = retriever.invoke(message)
        context = format_docs(docs)
        
        # T·∫°o chain v√† g·ªçi
        chain = prompt | llm | StrOutputParser()
        response = chain.invoke({
            "question": message,
            "context": context,
            "chat_history": chat_history
        })
        
        # C·∫≠p nh·∫≠t l·ªãch s·ª≠
        chat_history.append(HumanMessage(content=message))
        chat_history.append(AIMessage(content=response))
        
        # Gi·ªØ t·ªëi ƒëa 10 tin nh·∫Øn
        if len(chat_history) > 10:
            chat_history = chat_history[-10:]
        
        # Th√™m ngu·ªìn tham kh·∫£o
        sources = format_sources(docs)
        if sources:
            response += "\n\n---\n**üîç Ngu·ªìn tham kh·∫£o:**\n"
            response += "\n".join(f"- {s}" for s in sources)
        
        return response
        
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"


# =========================
# GRADIO UI (Gradio 6.0+)
# =========================
def main():
    demo = gr.ChatInterface(
        fn=chat_handler,
        title="üõçÔ∏è Uqilo Fashion Chatbot",
        description="Tr·ª£ l√Ω AI t∆∞ v·∫•n th·ªùi trang th√¥ng minh",
        examples=[
            "√Åo m√†u ƒë·ªè d∆∞·ªõi 300k",
            "Qu·∫ßn size L c√≤n h√†ng",
            "S·∫£n ph·∫©m ƒë√°nh gi√° tr√™n 4.5"
        ]
    )
    
    demo.launch(server_name="127.0.0.1", inbrowser=True)


if __name__ == "__main__":
    main()